# -*- coding: utf-8 -*-
"""
Created on Sun Nov  7 12:44:25 2021

@author: ov59opom
"""

import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns

# Example values for three lines, the last one without CI
cut_lengths = range(1, 17)

###### Accuracy Values
mean_line_stat_ACC = np.array([0.982294429708223, 0.982294429708223, 0.982294429708223, 0.982294429708223, 0.973710073710074, 0.973710073710074, 0.970866141732283, 0.970866141732283, 0.953448275862068, 0.953448275862068, 0.93103448275862, 0.93103448275862, 0.9375, 0.9375, 0.888888888888888, 0.888888888888888, ])
mean_line_seq_ACC = np.array([0.984084880636604, 0.990716180371352, 0.990716180371352, 0.996021220159151, 0.984275184275184, 0.993611793611793, 0.981889763779528, 0.989763779527559, 0.98103448275862, 0.994827586206896, 0.989655172413793, 0.989655172413793, 0.975, 0.975, 0.955555555555555, 0.944444444444444, ])
mean_line_RF_ACC = np.array([0.984084880636604, 0.984084880636604, 0.984084880636604, 0.984084880636604, 0.977886977886977, 0.977886977886977, 0.976377952755905, 0.976377952755905, 0.96551724137931, 0.96551724137931, 0.93103448275862, 0.93103448275862, 0.9375, 0.9375, 0.888888888888888, 0.888888888888888, ])
mean_line_NB_ACC = np.array([0.984084880636604, 0.984084880636604, 0.984084880636604, 0.984084880636604, 0.977886977886977, 0.977886977886977, 0.976377952755905, 0.976377952755905, 0.96551724137931, 0.96551724137931, 0.93103448275862, 0.93103448275862, 0.9375, 0.9375, 0.888888888888888, 0.888888888888888, ])
mean_line_LR_ACC = np.array([0.984084880636604, 0.990716180371352, 0.990716180371352, 0.996021220159151, 0.985257985257985, 0.992628992628992, 0.984251968503937, 0.992125984251968, 0.982758620689655, 0.982758620689655, 0.96551724137931, 0.96551724137931, 0.9375, 0.9375, 0.888888888888888, 0.888888888888888, ])
mean_line_KNN_ACC = np.array([0.984084880636604, 0.988726790450928, 0.988726790450928, 0.991379310344827, 0.982800982800982, 0.982800982800982, 0.984251968503937, 0.984251968503937, 0.96551724137931, 0.96551724137931, 0.93103448275862, 0.93103448275862, 0.875, 0.875, 0.888888888888888, 0.888888888888888, ])
mean_line_GB_ACC = np.array([0.984084880636604, 0.990716180371352, 0.990716180371352, 0.996021220159151, 0.985257985257985, 0.992628992628992, 0.984251968503937, 0.984251968503937, 0.982758620689655, 0.982758620689655, 0.96551724137931, 0.96551724137931, 0.9375, 0.9375, 0.888888888888888, 0.888888888888888, ])
mean_line_ADA_ACC = np.array([0.984084880636604, 0.990716180371352, 0.990716180371352, 0.996021220159151, 0.985257985257985, 0.995085995085995, 0.984251968503937, 0.992125984251968, 0.982758620689655, 0.982758620689655, 0.96551724137931, 0.96551724137931, 0.9375, 0.9375, 0.888888888888888, 0.888888888888888, ])
mean_line_complete_ACC = np.array([0.984084880636604, 0.990716180371352, 0.990716180371352, 0.996021220159151, 0.985257985257985, 0.994594594594595, 0.982677165354331, 0.989763779527559, 0.982758620689655, 0.998275862068965, 0.996551724137931, 0.993103448275862, 0.9875, 0.9875, 0.977777777777778, 0.966666666666666, ])

max_line_complete_ACC = np.array([0.984084880636604, 0.990716180371352, 0.990716180371352, 0.996021220159151, 0.985257985257985, 0.995577395577396, 0.985826771653543, 0.993372106846421, 0.982758620689655, 1.00344827586207, 1.00689655172414, 1.00689655172414, 1.0125, 1.0125, 1.02222222222222, 1.0175841743884, ])
min_line_complete_ACC = np.array([0.984084880636604, 0.990716180371352, 0.990716180371352, 0.996021220159151, 0.985257985257985, 0.993611793611793, 0.979527559055118, 0.986155452208696, 0.982758620689655, 0.993103448275862, 0.986206896551724, 0.979310344827586, 0.9625, 0.9625, 0.933333333333333, 0.915749158944934, ])




###### AUC Values
mean_line_stat_AUC = np.array([0.67749606918239, 0.67749606918239, 0.67749606918239, 0.67749606918239, 0.720993858179787, 0.720993858179787, 0.636290322580645, 0.636290322580645, 0.778571428571428, 0.778571428571428, 0.718518518518518, 0.718518518518518, 0.5, 0.5, 0.5125, 0.5125])
mean_line_seq_AUC = np.array([0.665978773584905, 0.820252133872416, 0.818519766397124, 0.893345687331536, 0.689335566722501, 0.892015633724176, 0.7, 0.708870967741935, 0.545535714285714, 0.950892857142857, 0.95, 0.95, 0.893333333333333, 0.893333333333333, 0.8875, 0.775])
mean_line_RF_AUC = np.array([0.72172619047619, 0.83512747079964, 0.843837039532794, 0.9275227425876, 0.783263539921831, 0.958654383026242, 0.843817204301075, 0.844892473118279, 0.740178571428571, 0.96875, 0.95, 0.944444444444444, 0.86, 0.813333333333333, 0.7875, 0.7])
mean_line_NB_AUC = np.array([0.708936994609164, 0.808555143755615, 0.810408243486073, 0.852818957771788, 0.724734785036292, 0.752652149637074, 0.744623655913978, 0.747311827956989, 0.580357142857142, 0.625, 0.574074074074074, 0.648148148148148, 0.133333333333333, 0.133333333333333, 0, 0])
mean_line_LR_AUC = np.array([0.723902178796046, 0.828686545372866, 0.835986635220125, 0.907176549865229, 0.743718592964824, 0.91680625348967, 0.71505376344086, 0.75, 0.571428571428571, 0.866071428571428, 0.833333333333333, 0.833333333333333, 0.533333333333333, 0.533333333333333, 0.5, 0.5])
mean_line_KNN_AUC = np.array([0.558625336927223, 0.735371743036837, 0.737168688230008, 0.795527291105121, 0.691652707984366, 0.80178671133445, 0.974462365591397, 0.978494623655914, 0.959821428571428, 0.950892857142857, 0.916666666666666, 0.916666666666666, 0.8, 0.766666666666666, 0.8125, 0.8125])
mean_line_GB_AUC = np.array([0.729826482479784, 0.811320754716981, 0.833195754716981, 0.899665880503144, 0.714405360134003, 0.901730876605248, 0.682795698924731, 0.71774193548387, 0.535714285714285, 0.955357142857142, 0.944444444444444, 0.925925925925925, 0.786666666666667, 0.786666666666667, 0.875, 0.875])
mean_line_ADA_AUC = np.array([0.73378537735849, 0.826875561545372, 0.835930480682839, 0.905211141060197, 0.760329424902289, 0.903405918481295, 0.712365591397849, 0.744623655913978, 0.571428571428571, 0.803571428571428, 0.777777777777777, 0.777777777777777, 0.533333333333333, 0.533333333333333, 0.5, 0.5])
mean_line_complete_AUC = np.array([0.71975516621743, 0.850642969451931, 0.858709568733153, 0.915491632973944, 0.749734785036292, 0.927414852037967, 0.751075268817204, 0.776612903225806, 0.6375, 1, 1, 1, 1, 1, 1, 0.9875])


max_line_complete_AUC = np.array([0.727785589502207, 0.864576923286653, 0.873276081953302, 0.924608097814432, 0.777440744089, 0.942963094851956, 0.792636877613092, 0.824451037682913, 0.703014058313728, 1, 1, 1, 1, 1, 1, 1.025])
min_line_complete_AUC = np.array([0.711724742932653, 0.83670901561721, 0.844143055513004, 0.906375168133455, 0.722028825983585, 0.911866609223978, 0.709513660021316, 0.728774768768699, 0.571985941686271, 1, 1, 1, 1, 1, 1, 0.95])


######

def plot_line_plots(cut_lengths, means_acc, mins_acc, maxes_acc, 
                    means_auc, mins_auc, maxes_auc, labels):
    palet = sns.color_palette("tab10")
    matplotlib.rcParams.update({'font.size': 24})
    
    fig, axs = plt.subplots(1, 2, figsize=(22, 10))
    ax1 = axs[0]
    ax2 = axs[1]
    
    def plot_on_axes(ax, m, a, b, title):
        for i, (mean, a, b, l) in enumerate(zip(m, a, b, labels)):
            if i == 0:
                ax.plot(cut_lengths, mean, color=palet[i], label=l)
            else:
                ax.plot(cut_lengths, mean, color=palet[i], linestyle='dashed', label=l)
            if len(a) > 0 and len(b) > 0:
                ax.fill_between(cut_lengths, a, b, alpha=.2, color=palet[i])
        # ax.set_title(r'$M_{%s}$' % target_activity_abbreviation, fontsize=30)
        # ax.set_xlabel('Size of Process Instance Prefix for Prediction')
        ax.set_xticks(np.arange(0, 15 + 1, step=5))
        ax.set_ylabel('Predictive performance')
        ax.set_ylim(0.45, 1.01)
        ax.title.set_text(title)
        
    plot_on_axes(ax1, means_acc, mins_acc, maxes_acc, title='Accuracy')
    plot_on_axes(ax2, means_auc, mins_auc, maxes_auc, title='AUC$_{ROC}$')
    
    ax1.legend(ncol=1, loc='lower left', 
           columnspacing=1.3, labelspacing=0.0,
           handletextpad=0.0, handlelength=1.5,
           fancybox=False, shadow=False)
    # ax2.set_yticks([])
    y_axis = ax2.axes.get_yaxis()
    y_axis.set_visible(False)

    fig.text(0.5, -0.01, 'Size of patient pathway prefix for prediction', ha='center')

    plt.tight_layout()
    plt.savefig('tmp.pdf', bbox_inches="tight")
    
    
# There are three args for acc and three args for auc
# Each arg is a list where the length equals the number of lines
# Each line is a list (or a 1D numpy array) with the y-values
# Pass an empty list in mins/maxes arg for a line not to have confidence intervals
plot_line_plots(cut_lengths, 
                means_acc = [mean_line_complete_ACC, mean_line_ADA_ACC,mean_line_GB_ACC,  mean_line_RF_ACC, mean_line_LR_ACC], 
                mins_acc = [ min_line_complete_ACC, [], [], [], []], 
                maxes_acc = [ max_line_complete_ACC, [],[],   [], []],
                means_auc = [mean_line_complete_AUC, mean_line_ADA_AUC, mean_line_GB_AUC, mean_line_RF_AUC, mean_line_LR_AUC],
                mins_auc = [ min_line_complete_AUC, [],[],  [], []], 
                maxes_auc = [ max_line_complete_AUC, [],[],  [], []],
                labels=['PatWay-Net $\pm$ SD', 'AdaBoost', 'Gradient Boosting', 'Random Forest',  'Logistic Regression'])